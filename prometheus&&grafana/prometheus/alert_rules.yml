# /opt/monitoring/prometheus/alert_rules.yml
groups:
  # =============================================================================
  # INFRASTRUCTURE ALERTS - Core system availability
  # =============================================================================
  - name: infrastructure.rules
    interval: 15s
    rules:
      # Service availability monitoring
      - alert: ServiceDown
        expr: up{job!="monitoring-vm",job!="vpn-node"} == 0
        for: 2m
        labels:
          severity: critical
          category: infrastructure
          impact: high
        annotations:
          summary: "üö® Service {{ $labels.job }} is DOWN"
          description: |
            Service {{ $labels.job }} at {{ $labels.instance }} has been unreachable for more than 2 minutes.
            
            ‚ö†Ô∏è **Impact Details:**
            - Service is completely unresponsive
            - Functionality provided by this service is unavailable
            - Connected systems may be affected
            
            üîç **Diagnostic Information:**
            - Status: DOWN
            - Duration: {{ $value | humanizeDuration }}
            - Job: {{ $labels.job }}
            - Instance: {{ $labels.instance }}
            - Last Successful Check: {{ $labels.last_success }}
            
            üîß **Recommended Actions:**
            1. Verify service process status
            2. Check service logs for errors
            3. Confirm network connectivity
            4. Inspect system resources
            5. Attempt service restart if necessary

      # Monitoring VM is down
      - alert: MonitoringVMDown
        expr: up{job="monitoring-vm"} == 0
        for: 2m
        labels:
          severity: critical
          category: infrastructure
          impact: critical
        annotations:
          summary: "üö® Monitoring System Down - Critical Infrastructure Alert"
          description: |
            The monitoring VM has become unreachable, impacting our ability to monitor all systems.
            
            ‚ö†Ô∏è **Critical Impact:**
            - Loss of system-wide monitoring capabilities
            - No visibility into other infrastructure components
            - Alert notifications may not be delivered
            - Metrics collection and storage interrupted
            
            üîß **Required Actions:**
            1. Verify VM power state and network connectivity
            2. Check system resources (CPU, Memory, Disk)
            3. Inspect Node Exporter service status
            4. Review system logs for errors
            5. If needed, safely restart monitoring services
            
            **Instance:** {{ $labels.instance }}
            **Duration:** {{ $value }}
            **Job:** {{ $labels.job }}

      # VPN b·ªã down
      - alert: VPNNodeDown
        expr: up{job="vpn-node"} == 0
        for: 30s
        labels:
          severity: critical
          category: infrastructure
          impact: critical
        annotations:
          summary: "üö® VPN Service Down - Remote Access Disrupted"
          description: |
            VPN service has been unreachable for more than 30 seconds.
            
            ‚ö†Ô∏è **Impact:**
            - Remote access to internal network is disrupted
            - Active VPN connections may be terminated
            - Remote workers cannot access internal resources
            
            üîß **Recommended Actions:**
            1. Check if VPN VM is powered on and responsive
            2. Verify network connectivity to 192.168.1.210
            3. Check VPN service logs for errors
            4. Restart VPN service if needed
            5. If issue persists, investigate system logs
            
            **Instance:** {{ $labels.instance }}
            **Duration:** {{ $value }}
            **Job:** {{ $labels.job }}

  # =============================================================================
  # RESOURCE ALERTS - CPU, Memory, Disk usage
  # =============================================================================
  - name: resource.rules
    interval: 15s
    rules:
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 75
        for: 10m
        labels:
          severity: warning
          category: resources
          impact: medium
        annotations:
          summary: "‚ö†Ô∏è High CPU usage on {{ $labels.instance }}"
          description: |
            CPU usage has been above 75% for more than 10 minutes.
            
            **Current Usage:** {{ $value | humanizePercentage }}
            **Threshold:** 75%
            **Instance:** {{ $labels.instance }}
            **Duration:** 10+ minutes
            
            üîç **Recommended Actions:**
            1. Check running processes (top/htop)
            2. Review system load
            3. Monitor for unusual activity
            4. Consider scaling resources if trend continues

      - alert: CriticalCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 5m
        labels:
          severity: critical
          category: resources
          impact: high
        annotations:
          summary: "üö® CRITICAL CPU usage on {{ $labels.instance }}"
          description: |
            CPU usage is critically high (>90%) for more than 5 minutes!
            
            **Current Usage:** {{ $value | humanizePercentage }}
            **Threshold:** 90%
            **Instance:** {{ $labels.instance }}
            
            ‚ö†Ô∏è **Impact:**
            - System performance severely degraded
            - Services may become unresponsive
            - User experience affected
            
            üîß **Immediate Actions Required:**
            1. Identify resource-intensive processes
            2. Kill/restart problematic services
            3. Check for system updates/patches
            4. Review recent changes/deployments

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
        for: 15m
        labels:
          severity: warning
          category: resources
          impact: medium
        annotations:
          summary: "‚ö†Ô∏è High memory usage on {{ $labels.instance }}"
          description: |
            Memory usage has been above 80% for more than 15 minutes.
            
            **Current Usage:** {{ $value | humanizePercentage }}
            **Available Memory:** {{ query "node_memory_MemAvailable_bytes{instance='$labels.instance'}" | first | value | humanizeBytes }}
            **Total Memory:** {{ query "node_memory_MemTotal_bytes{instance='$labels.instance'}" | first | value | humanizeBytes }}
            **Swap Usage:** {{ query "node_memory_SwapTotal_bytes{instance='$labels.instance'}" | first | value | humanizeBytes }}
            
            üîç **Check for:**
            - Memory leaks in applications
            - Excessive caching
            - Too many concurrent processes
            - Insufficient swap space

      - alert: CriticalMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
        for: 5m
        labels:
          severity: critical
          category: resources
          impact: high
        annotations:
          summary: "üö® CRITICAL memory usage on {{ $labels.instance }}"
          description: |
            Memory usage is critically high (>90%)! System stability at risk.
            
            **Current Usage:** {{ $value | humanizePercentage }}
            **Available Memory:** {{ query "node_memory_MemAvailable_bytes{instance='$labels.instance'}" | first | value | humanizeBytes }}
            **Swap Used:** {{ query "node_memory_SwapUsed_bytes{instance='$labels.instance'}" | first | value | humanizeBytes }}
            
            ‚ö†Ô∏è **Immediate Actions Required:**
            1. Clear system caches
            2. Restart memory-intensive services
            3. Check for memory leaks
            4. Consider OOM killer risks

      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 80
        for: 30m
        labels:
          severity: warning
          category: resources
          impact: medium
        annotations:
          summary: "‚ö†Ô∏è High disk usage on {{ $labels.instance }}"
          description: |
            Disk usage on {{ $labels.mountpoint }} has been above 80% for more than 30 minutes.
            
            **Current Usage:** {{ $value | humanizePercentage }}
            **Mount Point:** {{ $labels.mountpoint }}
            **Free Space:** {{ query "node_filesystem_free_bytes{instance='$labels.instance',mountpoint='$labels.mountpoint'}" | first | value | humanizeBytes }}
            **Inodes Free:** {{ query "node_filesystem_files_free{instance='$labels.instance',mountpoint='$labels.mountpoint'}" | first | value }}
            
            üîç **Recommended Actions:**
            1. Clear temporary files and caches
            2. Remove old logs and archives
            3. Check for large unused files
            4. Review backup retention policies

  # =============================================================================
  # NETWORK ALERTS - Connectivity and performance
  # =============================================================================
  - name: network.rules
    interval: 30s
    rules:
      - alert: HighNetworkReceive
        expr: rate(node_network_receive_bytes_total[5m]) > 10 * 1024 * 1024
        for: 5m
        labels:
          severity: warning
          category: network
          impact: low
        annotations:
          summary: "‚ö†Ô∏è High network receive on {{ $labels.instance }}"
          description: |
            Network interface {{ $labels.device }} is receiving more than 10MB/s for 5+ minutes.
            
            **Current Rate:** {{ $value | humanizeBytes }}/s
            **Interface:** {{ $labels.device }}
            **Instance:** {{ $labels.instance }}
            
            üîç **Possible Causes:**
            - Large file downloads/uploads
            - Backup operations
            - Network-intensive applications
            - Potential DDoS attack
            
            üìã **Recommended Actions:**
            1. Check running processes and network usage
            2. Monitor for unusual traffic patterns
            3. Review bandwidth allocation
            4. Verify expected network operations

      - alert: CriticalNetworkReceive
        expr: rate(node_network_receive_bytes_total[5m]) > 50 * 1024 * 1024
        for: 5m
        labels:
          severity: critical
          category: network
          impact: high
        annotations:
          summary: "üö® Critical network receive on {{ $labels.instance }}"
          description: |
            Network interface {{ $labels.device }} is receiving more than 50MB/s for 5+ minutes!
            
            **Current Rate:** {{ $value | humanizeBytes }}/s
            **Interface:** {{ $labels.device }}
            **Instance:** {{ $labels.instance }}
            **Total Received:** {{ query "node_network_receive_bytes_total{instance='$labels.instance',device='$labels.device'}" | first | value | humanizeBytes }}
            
            ‚ö†Ô∏è **Immediate Actions Required:**
            1. Check for unauthorized network activity
            2. Monitor system resources
            3. Review network security logs
            4. Consider rate limiting if necessary

      - alert: NetworkInterfaceErrors
        expr: rate(node_network_receive_errs_total[5m]) + rate(node_network_transmit_errs_total[5m]) > 0
        for: 5m
        labels:
          severity: warning
          category: network
          impact: medium
        annotations:
          summary: "‚ö†Ô∏è Network errors detected on {{ $labels.instance }}"
          description: |
            Network interface {{ $labels.device }} is experiencing errors.
            
            **Receive Errors:** {{ query "rate(node_network_receive_errs_total{instance='$labels.instance',device='$labels.device'}[5m])" | first | value | humanize }}
            **Transmit Errors:** {{ query "rate(node_network_transmit_errs_total{instance='$labels.instance',device='$labels.device'}[5m])" | first | value | humanize }}
            **Interface:** {{ $labels.device }}
            
            üîç **Possible Causes:**
            - Hardware issues
            - Driver problems
            - Network congestion
            - Cable/connection problems
            
            üìã **Recommended Actions:**
            1. Check network cables and connections
            2. Review network interface logs
            3. Monitor hardware status
            4. Consider interface replacement if persistent